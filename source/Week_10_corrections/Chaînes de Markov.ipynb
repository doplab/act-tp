{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4f67ce37c7731e8b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Chaînes de Markov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-90ec764d9a6d708b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercice\n",
    "\n",
    "Pour cet exercice, nous avons analysé le texte intégral de **Candide, ou l'Optimisme** de *Voltaire* afin de créer un dictionnaire qui se comporte comme une chaîne de Markov, où chaque mot peut être suivi d'un autre mot avec une probabilité `p`.\n",
    "Pour savoir quels mots suivent quel autre mot avec une certaine probabilité, vous pouvez utiliser `data[mot]` et voir quels mots le suivent.\n",
    "\n",
    "Par exemple `print(data[\"leibnitz\"])` affiche `{'navait': 0.5, 'ne': 0.5}`\n",
    "\n",
    "*En partant du mot `leibnitz`, dessinez une chaîne de Markov qui affiche les probabilités d'avoir un mot à la suite d'un autre.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1b67157b00e3ca66",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "class Candide:\n",
    "    _data = None\n",
    "    \n",
    "    @staticmethod\n",
    "    def data():\n",
    "        if Candide._data is None:\n",
    "            Candide.load_text()\n",
    "        return Candide._data\n",
    "    \n",
    "    @staticmethod\n",
    "    def clean_word(word):\n",
    "        return ''.join(l for l in word.lower().strip() if l.isalnum())\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_text():\n",
    "        with open(\"candide.txt\", \"r\") as file:\n",
    "            candide = file.read().split()\n",
    "            data = {}\n",
    "            for i in range(len(candide) - 1):\n",
    "                word = Candide.clean_word(candide[i])\n",
    "                next_word = Candide.clean_word(candide[i+1])\n",
    "                if word in data:\n",
    "                    if next_word in data[word]:\n",
    "                        data[word][next_word] += 1\n",
    "                    else:\n",
    "                        data[word][next_word] = 1\n",
    "                else:\n",
    "                    data[word] = {next_word: 1}\n",
    "            Candide._data = Candide.compute_stats(data)\n",
    "            \n",
    "    @staticmethod\n",
    "    def compute_stats(_data):\n",
    "        for i in _data.keys():\n",
    "            _sum = reduce(lambda accumulator, j: accumulator + _data[i][j], _data[i].keys(), 0)\n",
    "            for j in _data[i]:\n",
    "                _data[i][j] /= _sum\n",
    "        return _data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'leibnitz navait pas de la vieille je ne pouvait être autrement car il y a été pendu par le plus de la vieille je ne pouvait être autrement car il y a été pendu par le plus de la vieille je ne pouvait être autrement car il y a été pendu par le plus de la vieille je ne pouvait être autrement car il y a été pendu par le plus de la vieille je ne pouvait être autrement car il y a été pendu par le plus de la vieille je ne pouvait être autrement car il y a été pendu par le plus de'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Candide.data()\n",
    "\n",
    "def most_likely(word_data):\n",
    "    _max = 0\n",
    "    best = None\n",
    "    for next_word in word_data.keys():\n",
    "        if word_data[next_word] > _max:\n",
    "            best = next_word\n",
    "            _max = word_data[next_word]\n",
    "    return best\n",
    "\n",
    "def create_sentence(first_word, data, depth):\n",
    "    current_word = first_word\n",
    "    sentence = first_word\n",
    "    for i in range(depth):\n",
    "        current_word = most_likely(data[current_word]) # On appelle most_likely() ici\n",
    "        sentence = sentence + \" \" + current_word\n",
    "    return sentence\n",
    "\n",
    "create_sentence(\"leibnitz\", data, 105)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a643fe1213b4122c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercice\n",
    "\n",
    "Comme vous le voyez, votre phrase contient beaucoup de répétitions, car certains mots sont très fréquents (comme le mot `et`) et ils créent donc une boucle infinie.\n",
    "\n",
    "Pour empêcher ceci, faites en sorte que les mots soient choisis aléatoirement tout en respectant la probabilité qu'ils soit choisis. Vous pouvez utiliser une `table de probabilités`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'leibnitz ne soient bien que le tome xiii du siècle de leurs bouches se remirent messieurs les paraguains mangèrent du château de badajos dieu confonde la moindre valait mieux 2 les persans les convives étaient dassez larges pièces de lui accorda sa victoire mais comment en cet honnête il y reçoit assez des champs entre ses ennemis que la rade le chapitre xxviii page 126 b un vilain cimetière elle court surlechamp mais ils sembrassèrent en europe par lautre à lui dit candide de leffort quil ma donné les trois nègres quatre soldats du repos travaillons sans donner ordre aux procédures'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import random\n",
    "\n",
    "data = Candide.data()\n",
    "\n",
    "def proba_table(word_data, sentence):\n",
    "    cumulative = 0\n",
    "    r = random()\n",
    "    for word in word_data.keys():\n",
    "        proba = word_data[word]\n",
    "        if proba + cumulative > r:\n",
    "            return word\n",
    "        cumulative += proba\n",
    "\n",
    "def create_sentence(first_word, data, depth):\n",
    "    current_word = first_word\n",
    "    sentence = first_word\n",
    "    for i in range(depth):\n",
    "        current_word = proba_table(data[current_word], sentence) # On appelle probal_table() ici\n",
    "        sentence = sentence + \" \" + current_word\n",
    "    return sentence\n",
    "\n",
    "create_sentence(\"leibnitz\", data, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-914a50b90c48a7ca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercice\n",
    "\n",
    "Votre bon ami `Vladimir` vous propose d'investir `$10000` dans son business de \"plantes médicinales\".\n",
    "\n",
    "`Vladimir` est un revendeur très réputé dans votre quartier, cependant vous savez qu'il peut arriver que ses plantes ne soient pas toujours légales et du coup que vous risquez de vous faire arrêter en vous associant à lui.\n",
    "\n",
    "Vous estimez néanmoins qu'il peut être intéressant d'investir dans ce projet, cependant vous ne voulez pas prendre trop de risques. C'est pourquoi, vous investissez la somme `i`, tel que:\n",
    "\n",
    "$$ i < 10000 $$\n",
    "\n",
    "Soit `π`, un nombre qui correspond au pourcentage de votre investissement par rapport à `10000`, tel que:\n",
    "\n",
    "$$ \\pi = \\frac{\\mathrm{i} }{\\mathrm{10000} } $$\n",
    "\n",
    "Vous savez que tous les jours, votre investissement vous rapportera \n",
    "$$  r(\\pi) = \\pi^2  $$ \n",
    "\n",
    "\n",
    "Néanmoins, plus votre investissement est élevé, plus vos collègues vont se méfier de vos rendements, c'est pourquoi, tous les jours vous avez la probabilité `σ(π)` de vous faire arrêter:\n",
    "\n",
    "$$  \\sigma(\\pi) = \\frac{\\mathrm{1} }{\\mathrm{1} + e^{\\frac{\\mathrm{-\\pi}}{\\mathrm{5}}} } - \\frac{\\mathrm{1} }{\\mathrm{2} }  $$ \n",
    "\n",
    "## Créez un chaîne de Markov Monté Carlo qui détermine combien d'argent vous aurez après `T` périodes et quelle est la probabilité que vous vous fassiez arrêter durant ces `T` périodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.128, 7.818545104644229)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import exp\n",
    "from random import random\n",
    "\n",
    "def probability_prison(pi):\n",
    "    return 1/(1+exp(-pi/5)) - 1/2\n",
    "\n",
    "def run_simulation(pi, proba_prison):\n",
    "    bank = 0\n",
    "    for i in range(T):\n",
    "        r = random()\n",
    "        if r < proba_prison:\n",
    "            return -1\n",
    "        bank += r**2\n",
    "    return bank\n",
    "\n",
    "def markov_chain(i, pi, T):\n",
    "    _simulations = 1000\n",
    "    proba_prison = probability_prison(pi)\n",
    "    prisons = 0\n",
    "    bank = 0\n",
    "    for i in range(_simulations): # run 100 simulations\n",
    "        outcome = run_simulation(pi, proba_prison)\n",
    "        if outcome == -1:\n",
    "            prisons += 1\n",
    "        else:\n",
    "            bank = outcome\n",
    "    return (prisons/_simulations, bank)\n",
    "    \n",
    "i = 1000\n",
    "T = 30\n",
    "pi = i / 10000\n",
    "\n",
    "markov_chain(i, pi, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4f67ce37c7731e8b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Chaînes de Markov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-90ec764d9a6d708b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercice\n",
    "\n",
    "Pour cet exercice, nous avons analysé le texte intégral de **Candide, ou l'Optimisme** de *Voltaire* afin de créer un dictionnaire qui se comporte comme une chaîne de Markov, où chaque mot peut être suivi d'un autre mot avec une probabilité `p`.\n",
    "Pour savoir quels mots suivent quel autre mot avec une certaine probabilité, vous pouvez utiliser `data[mot]` et voir quels mots le suivent.\n",
    "\n",
    "Par exemple `print(data[\"leibnitz\"])` affiche `{'navait': 0.5, 'ne': 0.5}`\n",
    "\n",
    "*En partant du mot `leibnitz`, dessinez une chaîne de Markov qui affiche les probabilités d'avoir un mot à la suite d'un autre.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1b67157b00e3ca66",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "class Candide:\n",
    "    _data = None\n",
    "    \n",
    "    @staticmethod\n",
    "    def data():\n",
    "        if Candide._data is None:\n",
    "            Candide.load_text()\n",
    "        return Candide._data\n",
    "    \n",
    "    @staticmethod\n",
    "    def clean_word(word):\n",
    "        return ''.join(l for l in word.lower().strip() if l.isalnum())\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_text():\n",
    "        with open(\"candide.txt\", \"r\") as file:\n",
    "            candide = file.read().split()\n",
    "            data = {}\n",
    "            for i in range(len(candide) - 1):\n",
    "                word = Candide.clean_word(candide[i])\n",
    "                next_word = Candide.clean_word(candide[i+1])\n",
    "                if word in data:\n",
    "                    if next_word in data[word]:\n",
    "                        data[word][next_word] += 1\n",
    "                    else:\n",
    "                        data[word][next_word] = 1\n",
    "                else:\n",
    "                    data[word] = {next_word: 1}\n",
    "            Candide._data = Candide.compute_stats(data)\n",
    "            \n",
    "    @staticmethod\n",
    "    def compute_stats(_data):\n",
    "        for i in _data.keys():\n",
    "            _sum = reduce(lambda accumulator, j: accumulator + _data[i][j], _data[i].keys(), 0)\n",
    "            for j in _data[i]:\n",
    "                _data[i][j] /= _sum\n",
    "        return _data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Candide.data()\n",
    "\n",
    "def most_likely(word_data):\n",
    "    # word_data contient un dictionnaire avec les probabilités de chaque mot\n",
    "    # Retournez le mot avec la plus haute probabilité\n",
    "\n",
    "def create_sentence(first_word, data, depth):\n",
    "    current_word = first_word\n",
    "    sentence = first_word\n",
    "    for i in range(depth):\n",
    "        current_word = most_likely(data[current_word]) # On appelle most_likely() ici\n",
    "        sentence = sentence + \" \" + current_word\n",
    "    return sentence\n",
    "\n",
    "create_sentence(\"leibnitz\", data, 105)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a643fe1213b4122c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercice\n",
    "\n",
    "Comme vous le voyez, votre phrase contient beaucoup de répétitions, car certains mots sont très fréquents (comme le mot `et`) et ils créent donc une boucle infinie.\n",
    "\n",
    "Pour empêcher ceci, faites en sorte que les mots soient choisis aléatoirement tout en respectant la probabilité qu'ils soient choisis. Vous pouvez utiliser une `table de probabilités`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "data = Candide.data()\n",
    "\n",
    "def proba_table(word_data, sentence):\n",
    "    # Retournez un mot aléatoirement en fonction de sa probabilité d'arriver\n",
    "\n",
    "def create_sentence(first_word, data, depth):\n",
    "    current_word = first_word\n",
    "    sentence = first_word\n",
    "    for i in range(depth):\n",
    "        current_word = proba_table(data[current_word], sentence) # On appelle probal_table() ici\n",
    "        sentence = sentence + \" \" + current_word\n",
    "    return sentence\n",
    "\n",
    "create_sentence(\"leibnitz\", data, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-914a50b90c48a7ca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercice\n",
    "\n",
    "Votre bon ami `Vladimir` vous propose d'investir `$10000` dans son business de \"plantes médicinales\".\n",
    "\n",
    "`Vladimir` est un revendeur très réputé dans votre quartier, cependant vous savez qu'il peut arriver que ses plantes ne soient pas toujours légales et du coup que vous risquez de vous faire arrêter en vous associant à lui.\n",
    "\n",
    "Vous estimez néanmoins qu'il peut être intéressant d'investir dans ce projet, cependant vous ne voulez pas prendre trop de risques. C'est pourquoi, vous investissez la somme `i`, tel que:\n",
    "\n",
    "$$ i < 10000 $$\n",
    "\n",
    "Soit `π`, un nombre qui correspond au pourcentage de votre investissement par rapport à `10000`, tel que:\n",
    "\n",
    "$$ \\pi = \\frac{\\mathrm{i} }{\\mathrm{10000} } $$\n",
    "\n",
    "Vous savez que tous les jours, votre investissement vous rapportera \n",
    "$$  r(\\pi) = \\pi^2  $$ \n",
    "\n",
    "\n",
    "Néanmoins, plus votre investissement est élevé, plus vos collègues vont se méfier de vos rendements, c'est pourquoi, tous les jours vous avez la probabilité `σ(π)` de vous faire arrêter:\n",
    "\n",
    "$$  \\sigma(\\pi) = \\frac{\\mathrm{1} }{\\mathrm{1} + e^{\\frac{\\mathrm{-\\pi}}{\\mathrm{5}}} } - \\frac{\\mathrm{1} }{\\mathrm{2} }  $$ \n",
    "\n",
    "## Créez une chaîne de Markov Monté Carlo qui détermine combien d'argent vous aurez après `T` périodes. Quelle est la probabilité que vous vous fassiez arrêter durant ces `T` périodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "\n",
    "def probability_prison(pi):\n",
    "    return 1/(1+exp(-pi/5)) - 1/2\n",
    "\n",
    "def markov_chain(i, pi, T):\n",
    "    # Votre code ici\n",
    "    \n",
    "i = # VOTRE INVESTISSEMENT ICI\n",
    "T = # VOTRE NOMBRE DE PERIODES\n",
    "pi = i / 10000\n",
    "\n",
    "markov_chain(i, pi, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
